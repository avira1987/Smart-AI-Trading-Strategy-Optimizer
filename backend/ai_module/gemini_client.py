"""
Google Gemini AI client for strategy analysis and parsing
"""

import os
import json
import hashlib
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
from django.conf import settings

logger = logging.getLogger(__name__)

# Try to import google-generativeai
try:
    import google.generativeai as genai
except ImportError:
    genai = None
    logger.warning("google-generativeai not installed. Gemini features will be disabled.")

# Cache directory
_CACHE_DIR = Path(getattr(settings, 'CACHE_DIR', Path(__file__).parent.parent / 'cache' / 'gemini'))
_CACHE_DIR.mkdir(parents=True, exist_ok=True)

# System instructions
ANALYSIS_SYSTEM_INSTRUCTIONS = (
    "Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ú©Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ "
    "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:\n"
    "1. Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ\n"
    "2. Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ (Ù„ÛŒØ³Øª)\n"
    "3. Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ (Ù„ÛŒØ³Øª)\n"
    "4. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÛŒØ³Ú©\n"
    "5. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ (Ù„ÛŒØ³Øª)\n"
    "6. Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª (0-100)\n\n"
    "Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ ÛŒÚ© JSON Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:\n"
    '{"summary": "...", "strengths": [...], "weaknesses": [...], '
    '"risk_assessment": "...", "recommendations": [...], "quality_score": Ø¹Ø¯Ø¯}'
)

BACKTEST_ANALYSIS_SYSTEM_INSTRUCTIONS = (
    "Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ú©â€ŒØªØ³Øª Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ØªØ§ÛŒØ¬ Ø¨Ú©â€ŒØªØ³Øª Ùˆ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ØŒ "
    "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ùˆ Ù…ÙØµÙ„ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.\n\n"
    "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:\n"
    "1. ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©Ù„ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: Ú†Ù‚Ø¯Ø± Ø³ÙˆØ¯ ÛŒØ§ Ø¶Ø±Ø± Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŸ\n"
    "2. ØªØ­Ù„ÛŒÙ„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª: Ú†Ù†Ø¯ Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø±Ù†Ø¯Ù‡/Ø¨Ø§Ø²Ù†Ø¯Ù‡ Ø¯Ø§Ø´ØªØŸ Ù†Ø±Ø® Ø¨Ø±Ø¯ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ\n"
    "3. ØªØ­Ù„ÛŒÙ„ Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø´Ø±Ø· ÙˆØ±ÙˆØ¯/Ø®Ø±ÙˆØ¬ Ú©Ù‡ Ø¯Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ Ø¨Ú¯Ùˆ Ú©Ù‡:\n"
    "   - Ø§ÛŒÙ† Ø´Ø±Ø· Ú†Ù†Ø¯ Ø¨Ø§Ø± ÙØ¹Ø§Ù„ Ø´Ø¯Ù‡ Ø§Ø³ØªØŸ\n"
    "   - Ú†Ù‚Ø¯Ø± Ø³ÙˆØ¯Ø¢ÙˆØ± Ø¨ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ\n"
    "   - Ø¢ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ\n"
    "4. Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ØªØ§ÛŒØ¬ ÙˆØ§Ù‚Ø¹ÛŒ\n"
    "5. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯\n\n"
    "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚ØŒ Ø¬Ø§Ù…Ø¹ Ùˆ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ø¯."
)


def _hash_text(text: str) -> str:
    """Create hash for caching"""
    return hashlib.sha256(text.encode('utf-8')).hexdigest()


def _get_gemini_api_key() -> Optional[str]:
    """Get Gemini API key from database or settings"""
    from core.models import APIConfiguration
    
    try:
        api_config = APIConfiguration.objects.filter(
            provider='gemini',
            is_active=True
        ).first()
        
        if api_config and api_config.api_key:
            return api_config.api_key.strip()
    except Exception as e:
        logger.warning(f"Error getting API key from database: {e}")
    
    # Fallback to settings
    return getattr(settings, 'GEMINI_API_KEY', '')


def _init_client():
    """Initialize Gemini client"""
    if genai is None:
        return None
    
    api_key = _get_gemini_api_key()
    if not api_key:
        return None
    
    try:
        genai.configure(api_key=api_key)
        model_name = getattr(settings, 'GEMINI_MODEL', 'gemini-2.0-flash')
        return genai.GenerativeModel(model_name)
    except Exception as e:
        logger.error(f"Error initializing Gemini client: {e}")
        return None


def _client_ready() -> bool:
    """Check if Gemini client is ready"""
    if genai is None:
        return False
    
    gemini_enabled = getattr(settings, 'GEMINI_ENABLED', True)
    if not gemini_enabled:
        return False
    
    api_key = _get_gemini_api_key()
    if not api_key:
        return False
    
    return True


def parse_with_gemini(text: str) -> Optional[Dict[str, Any]]:
    """Parse strategy text using Gemini"""
    if not _client_ready():
        return None
    
    # Hash for caching
    digest = _hash_text(text[:4000])
    cache_file = _CACHE_DIR / f"parse_{digest}.json"
    
    if cache_file.exists():
        try:
            return json.loads(cache_file.read_text(encoding='utf-8'))
        except Exception:
            pass
    
    client = _init_client()
    if client is None:
        return None
    
    prompt = f"""
    Ø§ÛŒÙ† ÛŒÚ© Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ÛŒØ§ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. 
    Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯:
    
    {text[:4000]}
    
    Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ JSON Ø¨Ø§ Ø§ÛŒÙ† Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø´Ø¯:
    {{
        "entry_conditions": ["Ø´Ø±Ø· 1", "Ø´Ø±Ø· 2"],
        "exit_conditions": ["Ø´Ø±Ø· 1", "Ø´Ø±Ø· 2"],
        "indicators": ["RSI", "MACD"],
        "risk_management": {{"stop_loss": 50, "take_profit": 100}},
        "timeframe": "H1",
        "symbol": "EURUSD"
    }}
    
    ÙÙ‚Ø· JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯.
    """
    
    try:
        response = client.generate_content(
            prompt,
            generation_config={
                'temperature': 0.3,
                'max_output_tokens': getattr(settings, 'GEMINI_MAX_OUTPUT_TOKENS', 1024),
                'response_mime_type': 'application/json',
            },
        )
        
        content = response.text if hasattr(response, 'text') else None
        if not content:
            return None
        
        content_str = content.strip()
        if content_str.startswith('```'):
            content_str = content_str.strip('`')
            parts = content_str.split('\n', 1)
            content_str = parts[1] if len(parts) > 1 else parts[0]
        
        data = json.loads(content_str)
        
        # Cache result
        try:
            cache_file.write_text(json.dumps(data, ensure_ascii=False), encoding='utf-8')
        except Exception:
            pass
        
        return data
    except Exception as e:
        logger.warning(f"Gemini parsing failed: {e}")
        return None


def generate_basic_analysis(parsed_strategy: Dict[str, Any]) -> Dict[str, Any]:
    """Generate a basic analysis without AI - fallback when Gemini is not available"""
    entry_conditions = parsed_strategy.get('entry_conditions', [])
    exit_conditions = parsed_strategy.get('exit_conditions', [])
    risk_management = parsed_strategy.get('risk_management', {})
    indicators = parsed_strategy.get('indicators', [])
    
    summary = f"Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø´Ø§Ù…Ù„ {len(entry_conditions)} Ø´Ø±Ø· ÙˆØ±ÙˆØ¯ Ùˆ {len(exit_conditions)} Ø´Ø±Ø· Ø®Ø±ÙˆØ¬ Ø§Ø³Øª."
    if indicators:
        summary += f" Ø§Ø² Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ÛŒ {', '.join(indicators)} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
    
    strengths = []
    if entry_conditions:
        strengths.append("Ø¯Ø§Ø±Ø§ÛŒ Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯ Ù…Ø´Ø®Øµ Ø§Ø³Øª")
    if exit_conditions:
        strengths.append("Ø¯Ø§Ø±Ø§ÛŒ Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬ Ù…Ø´Ø®Øµ Ø§Ø³Øª")
    if risk_management:
        strengths.append("Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§Ø³Øª")
    
    weaknesses = []
    if not entry_conditions:
        weaknesses.append("Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯ Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª")
    if not exit_conditions:
        weaknesses.append("Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬ Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª")
    if not risk_management:
        weaknesses.append("Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© Ú©Ø§Ù…Ù„ Ù†ÛŒØ³Øª")
    
    risk_assessment = "Ø±ÛŒØ³Ú© Ù…ØªÙˆØ³Ø·"
    if not risk_management.get('stop_loss'):
        risk_assessment = "Ø±ÛŒØ³Ú© Ø¨Ø§Ù„Ø§ - Ø­Ø¯ Ø¶Ø±Ø± ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª"
    
    recommendations = []
    if not risk_management.get('stop_loss'):
        recommendations.append("ØªØ¹Ø±ÛŒÙ Ø­Ø¯ Ø¶Ø±Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©")
    if len(entry_conditions) < 2:
        recommendations.append("Ø§ÙØ²ÙˆØ¯Ù† Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯ Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‚Øª")
    
    quality_score = 50
    if entry_conditions and exit_conditions and risk_management:
        quality_score = 70
    if len(entry_conditions) > 2 and len(exit_conditions) > 1:
        quality_score = 80
    
    return {
        "summary": summary,
        "strengths": strengths,
        "weaknesses": weaknesses,
        "risk_assessment": risk_assessment,
        "recommendations": recommendations,
        "quality_score": quality_score / 100.0,
        "is_basic": True
    }


def analyze_strategy_with_gemini(parsed_strategy: Dict[str, Any], raw_text: str = None) -> Optional[Dict[str, Any]]:
    """Generate comprehensive analysis of a trading strategy using Gemini AI"""
    if not _client_ready():
        logger.warning("Gemini not available for strategy analysis")
        return None

    # Create a text description of the strategy for analysis
    strategy_description = f"""
Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:
- Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯: {', '.join(parsed_strategy.get('entry_conditions', []))}
- Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬: {', '.join(parsed_strategy.get('exit_conditions', []))}
- Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©: {parsed_strategy.get('risk_management', {})}
- Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§: {', '.join(parsed_strategy.get('indicators', []))}
- Ù†Ù…Ø§Ø¯: {parsed_strategy.get('symbol', 'ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø¯Ù‡')}
- ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: {parsed_strategy.get('timeframe', 'ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø¯Ù‡')}
- Ø§Ù…ØªÛŒØ§Ø² Ø§Ø¹ØªÙ…Ø§Ø¯: {parsed_strategy.get('confidence_score', 0.0) * 100:.0f}%
"""

    if raw_text:
        strategy_description += f"\nÙ…ØªÙ† Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:\n{raw_text[:2000]}"

    # Hash for caching
    digest = _hash_text(strategy_description)
    cache_file = _CACHE_DIR / f"analysis_{digest}.json"

    if cache_file.exists():
        try:
            return json.loads(cache_file.read_text(encoding='utf-8'))
        except Exception:
            pass

    client = _init_client()
    if client is None:
        return None

    prompt = (
        f"{ANALYSIS_SYSTEM_INSTRUCTIONS}\n\n"
        f"{strategy_description}\n\n"
        f"Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯."
    )

    try:
        response = client.generate_content(
            prompt,
            generation_config={
                'temperature': 0.7,
                'max_output_tokens': getattr(settings, 'GEMINI_MAX_OUTPUT_TOKENS', 2048),
                'response_mime_type': 'application/json',
            },
        )

        content = response.text if hasattr(response, 'text') else None
        if not content:
            return None

        # Parse JSON response
        content_str = content.strip()
        if content_str.startswith('```'):
            content_str = content_str.strip('`')
            parts = content_str.split('\n', 1)
            content_str = parts[1] if len(parts) > 1 else parts[0]

        data: Dict[str, Any] = json.loads(content_str)

        # Validate structure
        if not isinstance(data, dict):
            return None

        # Ensure all required fields exist
        if 'strengths' not in data:
            data['strengths'] = []
        if 'weaknesses' not in data:
            data['weaknesses'] = []
        if 'risk_assessment' not in data:
            data['risk_assessment'] = 'Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÛŒØ³Ú© Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'
        if 'recommendations' not in data:
            data['recommendations'] = []
        if 'summary' not in data:
            data['summary'] = 'ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'
        if 'quality_score' not in data:
            data['quality_score'] = 50
        
        # Convert quality_score to float if it's an integer
        if isinstance(data['quality_score'], int):
            data['quality_score'] = data['quality_score'] / 100.0
        elif isinstance(data['quality_score'], float) and data['quality_score'] > 1.0:
            data['quality_score'] = data['quality_score'] / 100.0

        try:
            cache_file.write_text(json.dumps(data, ensure_ascii=False), encoding='utf-8')
        except Exception:
            pass

        return data
    except Exception as e:
        logger.warning("Gemini strategy analysis failed: %s", e)
        return None


def generate_strategy_questions(
    parsed_strategy: Dict[str, Any],
    raw_text: str,
    existing_answers: Dict[str, Any] = None
) -> Optional[List[Dict[str, Any]]]:
    """ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Gemini"""
    logger.info("Starting question generation...")
    
    if not _client_ready():
        api_key = _get_gemini_api_key()
        if not api_key:
            logger.error("Gemini API key not found")
        if genai is None:
            logger.error("google-generativeai library not installed")
        logger.warning("Gemini not available for question generation")
        return None
    
    existing_answers = existing_answers or {}
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ
    strategy_summary = f"""
    Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡: {len(parsed_strategy.get('entry_conditions', []))} Ø´Ø±Ø·
    Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡: {len(parsed_strategy.get('exit_conditions', []))} Ø´Ø±Ø·
    Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§: {', '.join(parsed_strategy.get('indicators', []))}
    Ø§Ù…ØªÛŒØ§Ø² Ø§Ø¹ØªÙ…Ø§Ø¯: {parsed_strategy.get('confidence_score', 0) * 100:.0f}%
    """
    
    if existing_answers:
        strategy_summary += f"\nØ¬ÙˆØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ú©Ø§Ø±Ø¨Ø±:\n{json.dumps(existing_answers, ensure_ascii=False, indent=2)}"
    
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ú©Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ Ø¨Ø§ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ùˆ Ù‡Ø¯ÙÙ…Ù†Ø¯ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ú©Ù…Ú© Ú©Ù†Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø±Ø§ Ú©Ø§Ù…Ù„â€ŒØªØ± Ùˆ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± ØªØ¹Ø±ÛŒÙ Ú©Ù†Ø¯.
    
    Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:
    {strategy_summary}
    
    Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ (Ù‚Ø³Ù…Øª Ø§ÙˆÙ„):
    {raw_text[:3000]}
    
    **Ù‚ÙˆØ§Ù†ÛŒÙ† Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª:**
    
    1. **Ù‚Ø¨Ù„ Ø§Ø² ØªÙˆÙ„ÛŒØ¯ Ù‡Ø± Ø³ÙˆØ§Ù„ØŒ Ø§Ø¨ØªØ¯Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø¢ÛŒØ§ Ù¾Ø§Ø³Ø® Ø¢Ù† Ø³ÙˆØ§Ù„ Ø¯Ø± Ù…ØªÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡**
       - Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ø³ÙˆØ§Ù„ Ø¨Ù‡ Ø·ÙˆØ± ÙˆØ§Ø¶Ø­ Ùˆ Ú©Ø§Ù…Ù„ Ø¯Ø± Ù…ØªÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¢Ù…Ø¯Ù‡ Ø§Ø³ØªØŒ Ø¢Ù† Ø³ÙˆØ§Ù„ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù†Ú©Ù†ÛŒØ¯
       - ÙÙ‚Ø· Ø³ÙˆØ§Ù„Ø§ØªÛŒ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù¾Ø§Ø³Ø®Ø´Ø§Ù† Ø¯Ø± Ù…ØªÙ† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª ÛŒØ§ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø¨Ù‡Ù… Ø¨ÛŒØ§Ù† Ø´Ø¯Ù‡ Ø§Ø³Øª
    
    2. **Ù‡Ø¯Ù Ø´Ù…Ø§: ØªÙˆÙ„ÛŒØ¯ 3-5 Ø³ÙˆØ§Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©Ù‡:**
       - Ù†Ù‚Ø§Ø· Ù…Ø¨Ù‡Ù… Ùˆ Ù†Ø§Ù‚Øµ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†Ù†Ø¯ (Ù†Ù‡ Ú†ÛŒØ²Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ù…ØªÙ† ÙˆØ§Ø¶Ø­ Ù‡Ø³ØªÙ†Ø¯)
       - Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ú©Ù…Ú© Ú©Ù†Ù†Ø¯ Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯/Ø®Ø±ÙˆØ¬ Ø±Ø§ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± ØªØ¹Ø±ÛŒÙ Ú©Ù†Ù†Ø¯ (ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø± Ù…ØªÙ† Ù…Ø¨Ù‡Ù… Ø§Ø³Øª)
       - Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ù‡Ù… (Ù…Ø«Ù„ Ø­Ø¯ Ø¶Ø±Ø±ØŒ Ø­Ø¯ Ø³ÙˆØ¯ØŒ ØªØ§ÛŒÙ… ÙØ±ÛŒÙ…) Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†Ù†Ø¯ (ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø± Ù…ØªÙ† Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡)
       - Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù†Ù‡Ø§ Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†Ù†Ø¯ (ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø± Ù…ØªÙ† Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡)
    
    3. **Ù…Ø«Ø§Ù„:**
       - Ø§Ú¯Ø± Ø¯Ø± Ù…ØªÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ "Ø­Ø¯ Ø¶Ø±Ø± 50 Ù¾ÛŒÙ¾ Ø§Ø³Øª"ØŒ Ø³ÙˆØ§Ù„ "Ø­Ø¯ Ø¶Ø±Ø± Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ" Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù†Ú©Ù†ÛŒØ¯
       - Ø§Ú¯Ø± Ø¯Ø± Ù…ØªÙ† Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ "Ø§Ø² Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± RSI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…"ØŒ Ø³ÙˆØ§Ù„ "Ú©Ø¯Ø§Ù… Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ" Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù†Ú©Ù†ÛŒØ¯
       - ÙÙ‚Ø· Ø³ÙˆØ§Ù„Ø§ØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù¾Ø§Ø³Ø®Ø´Ø§Ù† Ø¯Ø± Ù…ØªÙ† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª
    
    Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ ÛŒÚ© JSON Ø¨Ø§ Ø§ÛŒÙ† Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø´Ø¯:
    {{
      "questions": [
        {{
          "question_text": "Ù…ØªÙ† Ø³ÙˆØ§Ù„ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ",
          "question_type": "text|number|choice|multiple_choice|boolean",
          "options": ["Ú¯Ø²ÛŒÙ†Ù‡ 1", "Ú¯Ø²ÛŒÙ†Ù‡ 2"] (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ choice Ùˆ multiple_choice),
          "order": 1,
          "context": {{
            "section": "entry|exit|risk|indicator",
            "related_text": "Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…ØªÙ† Ú©Ù‡ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ø§Ø³Øª"
          }}
        }}
      ]
    }}
    
    Ù†Ú©Ø§Øª Ù…Ù‡Ù…:
    - Ø³ÙˆØ§Ù„Ø§Øª Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ùˆ ÙˆØ§Ø¶Ø­ Ø¨Ø§Ø´Ù†Ø¯
    - Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ø¯Ø¯ÛŒ (Ù…Ø«Ù„ Ø­Ø¯ Ø¶Ø±Ø±ØŒ Ø­Ø¯ Ø³ÙˆØ¯) Ø§Ø² Ù†ÙˆØ¹ "number" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
    - Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¨Ù„Ù‡/Ø®ÛŒØ± Ø§Ø² Ù†ÙˆØ¹ "boolean" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
    - Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø² Ú†Ù†Ø¯ Ú¯Ø²ÛŒÙ†Ù‡ Ø§Ø² "choice" Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
    - ØªØ±ØªÛŒØ¨ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ù‡Ù… Ø§Ø³Øª (Ø§Ø² Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯)
    - Ø§Ú¯Ø± Ø¬ÙˆØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯ Ù†Ø¨Ø§ÛŒØ¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ø§Ø´Ù†Ø¯
    - **Ù…Ù‡Ù…: ÙÙ‚Ø· Ø³ÙˆØ§Ù„Ø§ØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù¾Ø§Ø³Ø®Ø´Ø§Ù† Ø¯Ø± Ù…ØªÙ† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª**
    
    ÙÙ‚Ø· JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ.
    """
    
    client = _init_client()
    if client is None:
        logger.error("Failed to initialize Gemini client")
        return None
    
    try:
        logger.info("Sending request to Gemini API...")
        response = client.generate_content(
            prompt,
            generation_config={
                'temperature': 0.7,
                'max_output_tokens': getattr(settings, 'GEMINI_MAX_OUTPUT_TOKENS', 2048),
                'response_mime_type': 'application/json',
            },
        )
        
        logger.info("Received response from Gemini API")
        content = response.text if hasattr(response, 'text') else None
        if not content:
            logger.error("Gemini API returned empty response")
            return None
        
        # Parse JSON
        content_str = content.strip()
        if content_str.startswith('```'):
            content_str = content_str.strip('`')
            parts = content_str.split('\n', 1)
            content_str = parts[1] if len(parts) > 1 else parts[0]
        
        try:
            data: Dict[str, Any] = json.loads(content_str)
        except json.JSONDecodeError as json_error:
            logger.error(f"Failed to parse JSON response: {json_error}")
            logger.error(f"Response content: {content_str[:500]}")
            return None
        
        if not isinstance(data, dict) or 'questions' not in data:
            logger.error(f"Invalid response structure. Expected 'questions' key. Got: {list(data.keys()) if isinstance(data, dict) else type(data)}")
            return None
        
        questions = data['questions']
        if not isinstance(questions, list):
            logger.error(f"Questions is not a list. Got: {type(questions)}")
            return None
        
        if len(questions) == 0:
            logger.warning("Gemini returned empty questions list")
            return None
        
        logger.info(f"Successfully generated {len(questions)} questions")
        return questions
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"Gemini question generation failed: {str(e)}\n{error_trace}")
        return None


def parse_strategy_with_answers(
    parsed_strategy: Dict[str, Any],
    raw_text: str,
    answers: Dict[str, Any]
) -> Dict[str, Any]:
    """ØªØ¨Ø¯ÛŒÙ„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¬ÙˆØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ùˆ Gemini"""
    if not _client_ready():
        logger.warning("Gemini not available for strategy conversion")
        return parsed_strategy
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø±Ø§ÛŒ Gemini
    strategy_info = f"""
    Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:
    {chr(10).join(f'- {c}' for c in parsed_strategy.get('entry_conditions', []))}
    
    Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:
    {chr(10).join(f'- {c}' for c in parsed_strategy.get('exit_conditions', []))}
    
    Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§: {', '.join(parsed_strategy.get('indicators', []))}
    Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©: {json.dumps(parsed_strategy.get('risk_management', {}), ensure_ascii=False)}
    """
    
    answers_text = f"""
    Ø¬ÙˆØ§Ø¨â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±:
    {json.dumps(answers, ensure_ascii=False, indent=2)}
    """
    
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ù…Ø¨Ø¯Ù„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…ØªÙ†ÛŒ (ÙØ§Ø±Ø³ÛŒ/Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ) Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ù…Ø¯Ù„ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯.
    
    Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:
    {strategy_info}
    
    {answers_text}
    
    Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:
    {raw_text[:4000]}
    
    Ù‡Ø¯Ù: ØªØ¨Ø¯ÛŒÙ„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù‡ ÛŒÚ© Ø³Ø§Ø®ØªØ§Ø± JSON Ú©Ø§Ù…Ù„ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ú©Ù‡ Ø´Ø§Ù…Ù„:
    1. Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§
    2. Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§
    3. Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚
    4. Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú© Ú©Ø§Ù…Ù„
    5. ÛŒÚ© Ù…Ø¯Ù„ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨ØªÙˆØ§Ù†Ø¯ Ø¨Ø§ Ø¢Ù† ØªØ±ÛŒØ¯ Ú©Ù†Ø¯
    
    Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ JSON Ø¨Ø§ Ø§ÛŒÙ† Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø´Ø¯:
    {{
      "entry_conditions": [
        {{
          "condition": "Ø´Ø±Ø· Ø¨Ù‡ ØµÙˆØ±Øª Ù…ØªÙ†",
          "type": "indicator|price_action|pattern|custom",
          "params": {{}},
          "code_snippet": "Ú©Ø¯ Python Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)"
        }}
      ],
      "exit_conditions": [...],
      "indicators": {{
        "rsi": {{"period": 14}},
        "macd": {{"fast": 12, "slow": 26, "signal": 9}}
      }},
      "risk_management": {{
        "stop_loss": {{"type": "pips|percentage|price", "value": 50}},
        "take_profit": {{"type": "pips|percentage|price", "value": 100}},
        "risk_per_trade": 2
      }},
      "executable_model": {{
        "entry_logic": "Ù…Ù†Ø·Ù‚ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ ØµÙˆØ±Øª Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§",
        "exit_logic": "Ù…Ù†Ø·Ù‚ Ø®Ø±ÙˆØ¬ Ø¨Ù‡ ØµÙˆØ±Øª Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§"
      }}
    }}
    
    ÙÙ‚Ø· JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯.
    """
    
    client = _init_client()
    if client is None:
        return parsed_strategy
    
    try:
        response = client.generate_content(
            prompt,
            generation_config={
                'temperature': 0.3,
                'max_output_tokens': getattr(settings, 'GEMINI_MAX_OUTPUT_TOKENS', 4096),
                'response_mime_type': 'application/json',
            },
        )
        
        content = response.text if hasattr(response, 'text') else None
        if not content:
            return parsed_strategy
        
        content_str = content.strip()
        if content_str.startswith('```'):
            content_str = content_str.strip('`')
            parts = content_str.split('\n', 1)
            content_str = parts[1] if len(parts) > 1 else parts[0]
        
        enhanced_strategy: Dict[str, Any] = json.loads(content_str)
        
        # Merge with original parsed strategy
        merged = dict(parsed_strategy)
        merged.update(enhanced_strategy)
        
        return merged
        
    except Exception as e:
        logger.warning(f"Gemini strategy conversion failed: {e}")
        return parsed_strategy


def analyze_backtest_trades_with_ai(
    backtest_results: Dict[str, Any],
    strategy: Dict[str, Any],
    symbol: str
) -> Optional[str]:
    """Analyze backtest trades using AI (Gemini) and return Persian text analysis."""
    if not _client_ready():
        logger.warning("Gemini not available for backtest analysis")
        return None
    
    # Prepare comprehensive backtest data for analysis
    total_trades = backtest_results.get('total_trades', 0)
    winning_trades = backtest_results.get('winning_trades', 0)
    losing_trades = backtest_results.get('losing_trades', 0)
    total_return = backtest_results.get('total_return', 0.0)
    win_rate = backtest_results.get('win_rate', 0.0)
    max_drawdown = backtest_results.get('max_drawdown', 0.0)
    sharpe_ratio = backtest_results.get('sharpe_ratio', 0.0)
    profit_factor = backtest_results.get('profit_factor', 0.0)
    
    trades = backtest_results.get('trades', [])
    
    # Strategy info
    entry_conditions = strategy.get('entry_conditions', [])
    exit_conditions = strategy.get('exit_conditions', [])
    risk_management = strategy.get('risk_management', {})
    
    # Create analysis data
    analysis_data = {
        "total_trades": total_trades,
        "winning_trades": winning_trades,
        "losing_trades": losing_trades,
        "win_rate": win_rate,
        "total_return": total_return,
        "max_drawdown": max_drawdown,
        "sharpe_ratio": sharpe_ratio,
        "profit_factor": profit_factor,
        "entry_conditions": entry_conditions,
        "exit_conditions": exit_conditions,
        "risk_management": risk_management,
        "symbol": symbol,
        "sample_trades": trades[:10] if trades else []
    }
    
    # Hash for caching
    digest = _hash_text(json.dumps(analysis_data, sort_keys=True))
    cache_file = _CACHE_DIR / f"backtest_analysis_{digest}.txt"
    
    if cache_file.exists():
        try:
            return cache_file.read_text(encoding='utf-8')
        except Exception:
            pass
    
    prompt = (
        f"{BACKTEST_ANALYSIS_SYSTEM_INSTRUCTIONS}\n\n"
        f"Ù†ØªØ§ÛŒØ¬ Ø¨Ú©â€ŒØªØ³Øª:\n{json.dumps(analysis_data, ensure_ascii=False, indent=2)}\n\n"
        f"Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯."
    )
    
    client = _init_client()
    if client is None:
        return None
    
    try:
        response = client.generate_content(
            prompt,
            generation_config={
                'temperature': 0.7,
                'max_output_tokens': getattr(settings, 'GEMINI_MAX_OUTPUT_TOKENS', 4096),
            },
        )
        
        analysis_text = response.text if hasattr(response, 'text') else None
        if not analysis_text:
            return None
        
        analysis_text = analysis_text.strip()
        if analysis_text.startswith('```'):
            analysis_text = analysis_text.strip('`')
            parts = analysis_text.split('\n', 1)
            analysis_text = parts[1] if len(parts) > 1 else parts[0]
        
        # Cache result
        try:
            cache_file.write_text(analysis_text, encoding='utf-8')
        except Exception:
            pass
        
        return analysis_text
    except Exception as e:
        logger.warning("Gemini backtest analysis failed: %s", e)
        return None


def generate_basic_backtest_analysis(backtest_results: Dict[str, Any], strategy: Dict[str, Any], symbol: str) -> str:
    """Generate a basic backtest analysis without AI - fallback when Gemini is not available"""
    total_trades = backtest_results.get('total_trades', 0)
    winning_trades = backtest_results.get('winning_trades', 0)
    losing_trades = backtest_results.get('losing_trades', 0)
    total_return = backtest_results.get('total_return', 0.0)
    win_rate = backtest_results.get('win_rate', 0.0)
    max_drawdown = backtest_results.get('max_drawdown', 0.0)
    
    entry_conditions = strategy.get('entry_conditions', [])
    exit_conditions = strategy.get('exit_conditions', [])
    
    analysis = f"ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ú©â€ŒØªØ³Øª Ø¨Ø±Ø§ÛŒ {symbol}\n\n"
    analysis += "=" * 80 + "\n\n"
    
    if total_trades > 0:
        analysis += f"ğŸ“ˆ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:\n"
        analysis += f"- ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {total_trades}\n"
        analysis += f"- Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø±Ù†Ø¯Ù‡: {winning_trades}\n"
        analysis += f"- Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§Ø²Ù†Ø¯Ù‡: {losing_trades}\n"
        analysis += f"- Ù†Ø±Ø® Ø¨Ø±Ø¯: {win_rate:.2f}%\n\n"
        
        if winning_trades > losing_trades:
            analysis += f"âœ… Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø«Ø¨ØªÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª. {winning_trades} Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø±Ù†Ø¯Ù‡ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ {losing_trades} Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø§Ø²Ù†Ø¯Ù‡.\n\n"
        elif losing_trades > winning_trades:
            analysis += f"âš ï¸ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯. {losing_trades} Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø§Ø²Ù†Ø¯Ù‡ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ {winning_trades} Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø±Ù†Ø¯Ù‡.\n\n"
        else:
            analysis += f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø±Ù†Ø¯Ù‡ Ùˆ Ø¨Ø§Ø²Ù†Ø¯Ù‡ Ø¨Ø±Ø§Ø¨Ø± Ø§Ø³Øª.\n\n"
        
        if total_return > 0:
            analysis += f"ğŸ’¹ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒØŒ Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø´Ù…Ø§ {total_return:.2f}% Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØªÙ‡ Ø§Ø³Øª.\n\n"
        elif total_return < 0:
            analysis += f"ğŸ“‰ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¨Ø§ Ø§ÛŒÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒØŒ Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø´Ù…Ø§ {abs(total_return):.2f}% Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø§Ø³Øª.\n\n"
        else:
            analysis += f"â¡ï¸ Ø§ÛŒÙ† Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø³ÙˆØ¯ ÛŒØ§ Ø¶Ø±Ø± Ø®Ø§ØµÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.\n\n"
    else:
        analysis += "âš ï¸ Ù‡ÛŒÚ† Ù…Ø¹Ø§Ù…Ù„Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ú©â€ŒØªØ³Øª Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯ ÛŒØ§ Ø®Ø±ÙˆØ¬ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯.\n\n"
    
    # Strategy analysis
    if entry_conditions or exit_conditions:
        analysis += f"ğŸ“‹ ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:\n"
        analysis += f"- ØªØ¹Ø¯Ø§Ø¯ Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯: {len(entry_conditions)}\n"
        analysis += f"- ØªØ¹Ø¯Ø§Ø¯ Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬: {len(exit_conditions)}\n\n"
        
        if entry_conditions:
            analysis += "Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯:\n"
            for idx, cond in enumerate(entry_conditions[:5], 1):
                analysis += f"  {idx}. {cond[:100]}...\n"
            analysis += "\n"
        
        if exit_conditions:
            analysis += "Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬:\n"
            for idx, cond in enumerate(exit_conditions[:5], 1):
                analysis += f"  {idx}. {cond[:100]}...\n"
            analysis += "\n"
    
    # Trade analysis if available
    trades = backtest_results.get('trades', [])
    if trades:
        profits = [t.get('profit', 0) for t in trades if t.get('profit', 0) > 0]
        losses = [t.get('profit', 0) for t in trades if t.get('profit', 0) < 0]
        
        if profits:
            avg_profit = sum(profits) / len(profits)
            analysis += f"ğŸ’° Ù…ØªÙˆØ³Ø· Ø³ÙˆØ¯ Ù‡Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø±Ù†Ø¯Ù‡: {avg_profit:.2f}\n"
        
        if losses:
            avg_loss = abs(sum(losses) / len(losses))
            analysis += f"ğŸ“‰ Ù…ØªÙˆØ³Ø· Ø¶Ø±Ø± Ù‡Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø§Ø²Ù†Ø¯Ù‡: {avg_loss:.2f}\n"
    
    analysis += "\n" + "=" * 80
    analysis += "\n\nğŸ’¡ ØªÙˆØµÛŒÙ‡: Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù‡Ø± Ø´Ø±Ø· ÙˆØ±ÙˆØ¯/Ø®Ø±ÙˆØ¬ØŒ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
    
    return analysis


def generate_ai_recommendations(
    parsed_strategy: Dict[str, Any],
    raw_text: str = None,
    analysis: Dict[str, Any] = None
) -> Optional[List[Dict[str, Any]]]:
    """
    Generate AI recommendations for improving the strategy
    Each recommendation costs 150,000 Toman
    """
    if not _client_ready():
        logger.warning("Gemini not available for recommendations generation")
        return None
    
    # Prepare strategy information
    strategy_info = f"""
    Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ:
    - Ø´Ø±Ø§ÛŒØ· ÙˆØ±ÙˆØ¯: {', '.join(parsed_strategy.get('entry_conditions', []))}
    - Ø´Ø±Ø§ÛŒØ· Ø®Ø±ÙˆØ¬: {', '.join(parsed_strategy.get('exit_conditions', []))}
    - Ù…Ø¯ÛŒØ±ÛŒØª Ø±ÛŒØ³Ú©: {json.dumps(parsed_strategy.get('risk_management', {}), ensure_ascii=False)}
    - Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§: {', '.join(parsed_strategy.get('indicators', []))}
    - Ù†Ù…Ø§Ø¯: {parsed_strategy.get('symbol', 'ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø¯Ù‡')}
    - ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: {parsed_strategy.get('timeframe', 'ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø¯Ù‡')}
    """
    
    if raw_text:
        strategy_info += f"\nÙ…ØªÙ† Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:\n{raw_text[:2000]}"
    
    if analysis:
        strategy_info += f"\n\nØªØ­Ù„ÛŒÙ„ ÙØ¹Ù„ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ:\n{json.dumps(analysis, ensure_ascii=False)}"
    
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ù…Ø´Ø§ÙˆØ± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø²ÛŒØ±ØŒ 3-5 Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¹Ù…Ù„ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
    
    {strategy_info}
    
    Ù‡Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø§ÛŒØ¯:
    1. ÛŒÚ© Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ø¶Ø­ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
    2. ØªÙˆØ¶ÛŒØ­ Ú©Ø§Ù…Ù„ÛŒ Ø§Ø² Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯
    3. Ù†ÙˆØ¹ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†Ø¯ (entry_condition, exit_condition, risk_management, indicator, parameter, general)
    4. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
    
    Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ JSON Ø¨Ø§ Ø§ÛŒÙ† Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø´Ø¯:
    {{
      "recommendations": [
        {{
          "title": "Ø¹Ù†ÙˆØ§Ù† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯",
          "description": "ØªÙˆØ¶ÛŒØ­ Ú©Ø§Ù…Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯",
          "type": "entry_condition|exit_condition|risk_management|indicator|parameter|general",
          "data": {{
            "suggested_value": "Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ",
            "implementation": "Ø±ÙˆØ´ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ",
            "expected_improvement": "Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±"
          }}
        }}
      ]
    }}
    
    ÙÙ‚Ø· JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ.
    """
    
    client = _init_client()
    if client is None:
        return None
    
    try:
        response = client.generate_content(
            prompt,
            generation_config={
                'temperature': 0.8,
                'max_output_tokens': getattr(settings, 'GEMINI_MAX_OUTPUT_TOKENS', 4096),
                'response_mime_type': 'application/json',
            },
        )
        
        content = response.text if hasattr(response, 'text') else None
        if not content:
            return None
        
        content_str = content.strip()
        if content_str.startswith('```'):
            content_str = content_str.strip('`')
            parts = content_str.split('\n', 1)
            content_str = parts[1] if len(parts) > 1 else parts[0]
        
        data: Dict[str, Any] = json.loads(content_str)
        
        if not isinstance(data, dict) or 'recommendations' not in data:
            return None
        
        recommendations = data['recommendations']
        if not isinstance(recommendations, list):
            return None
        
        return recommendations
        
    except Exception as e:
        logger.error(f"Error generating AI recommendations: {str(e)}")
        return None
